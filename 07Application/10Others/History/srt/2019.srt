1
00:00:00,000 --> 00:00:01,083
2019年说实话

2
00:00:01,083 --> 00:00:03,283
AI在最重要的就是在NLP

3
00:00:03,600 --> 00:00:06,566
也就是自然语言处理相关的领域

4
00:00:06,566 --> 00:00:07,450
发布了GPT2

5
00:00:07,450 --> 00:00:08,883
内容/录制:Z0MI酱，视频剪辑/字幕:梁嘉铭

6
00:00:08,883 --> 00:00:09,366
哈喽大家好

7
00:00:09,366 --> 00:00:13,366
我发现这一期系列的那个AI大事业

8
00:00:13,366 --> 00:00:14,966
回顾没什么人看

9
00:00:14,966 --> 00:00:15,566
whatever

10
00:00:15,566 --> 00:00:18,233
ZOMI还是坚持做自己想要做的事情

11
00:00:18,233 --> 00:00:19,600
毕竟开了个头嘛

12
00:00:19,600 --> 00:00:21,083
还是得想结束下去

13
00:00:21,083 --> 00:00:23,400
回顾过去AI的十年的发展

14
00:00:23,800 --> 00:00:24,400
那我们现在

15
00:00:24,400 --> 00:00:26,000
来到了第一个内容

16
00:00:26,000 --> 00:00:28,483
也就是2019年所发生的很重要的事情

17
00:00:28,483 --> 00:00:31,400
就是算法跟模型相关的一些发展

18
00:00:31,433 --> 00:00:33,200
首先 2019年最重要的事情

19
00:00:33,200 --> 00:00:35,966
就是自然语言处理NLP的整体的突破

20
00:00:36,033 --> 00:00:37,366
那这个整体的突破

21
00:00:37,366 --> 00:00:38,766
最具有代表性意义

22
00:00:38,766 --> 00:00:42,200
就是Bert E E R T这个网络模型

23
00:00:42,200 --> 00:00:44,033
那在2019年的时候

24
00:00:44,033 --> 00:00:45,233
Bert这个网络模型

25
00:00:45,233 --> 00:00:47,966
成为整个NLP领域的整体的标杆

26
00:00:47,966 --> 00:00:50,400
它的预训练跟微调这种模式

27
00:00:50,400 --> 00:00:52,633
被广泛的应用到问答系统

28
00:00:52,633 --> 00:00:54,766
文本分列了等多任务里面

29
00:00:54,766 --> 00:00:56,233
整体推动了NLP

30
00:00:56,233 --> 00:00:58,316
自然语言处理的一个快速的进展

31
00:00:58,516 --> 00:01:01,283
我们现在经常聊到的大模型的预训练

32
00:01:01,316 --> 00:01:04,166
和微调SFT相关的概念

33
00:01:04,166 --> 00:01:05,233
就是从Bert

34
00:01:05,283 --> 00:01:07,916
2019年这个网络模型所开启

35
00:01:08,083 --> 00:01:09,800
那接着Bert之后

36
00:01:09,800 --> 00:01:12,000
百度基于Bert提出了ERINE

37
00:01:12,000 --> 00:01:14,883
它的一个知识增强的语义理解模型

38
00:01:14,883 --> 00:01:17,316
ERNIE那整体的这个模型

39
00:01:17,316 --> 00:01:18,883
通过外部的知识图谱

40
00:01:18,883 --> 00:01:21,233
提升了模型对语义的理解能力

41
00:01:21,233 --> 00:01:23,966
整体是超越了谷歌的Bert模型

42
00:01:24,083 --> 00:01:25,516
那整体来说

43
00:01:25,883 --> 00:01:28,633
在2019年 最核心的就是BERT的开源

44
00:01:28,716 --> 00:01:30,000
跟广泛的应用

45
00:01:30,000 --> 00:01:32,800
推动了整个NLP领域的快速发展

46
00:01:32,883 --> 00:01:36,033
为后续启发了一系列改进的模型

47
00:01:36,033 --> 00:01:37,083
例如roBert

48
00:01:37,083 --> 00:01:39,283
AlBert各种各样的变种

49
00:01:39,916 --> 00:01:41,483
接着我们看一下整

50
00:01:41,483 --> 00:01:43,566
个Transformer架构的一个统治

51
00:01:43,566 --> 00:01:45,000
在2019年的时候

52
00:01:45,000 --> 00:01:46,233
刚才聊到的Bert

53
00:01:46,233 --> 00:01:47,600
Vobert、GPT2

54
00:01:47,633 --> 00:01:49,800
还有Vobeta相关的模型

55
00:01:49,800 --> 00:01:52,433
全部都是基于Transformer的一个架构

56
00:01:52,433 --> 00:01:54,166
所以整个Transformer的架构

57
00:01:54,166 --> 00:01:55,233
在NLP领域

58
00:01:55,233 --> 00:01:57,366
已经取得了显著的发展

59
00:01:57,366 --> 00:01:59,800
而且很多是基于Transformer架构

60
00:01:59,800 --> 00:02:01,400
并且利用Bert的风格

61
00:02:01,400 --> 00:02:04,000
进行一个双向编码的架构的格式

62
00:02:04,033 --> 00:02:05,166
那这些模型

63
00:02:05,166 --> 00:02:08,116
都在多项的一个标准的测试集当中

64
00:02:08,116 --> 00:02:09,633
刷新了新的记录

65
00:02:09,966 --> 00:02:12,566
甚至在GLUE的测试集当中

66
00:02:12,566 --> 00:02:14,600
超越了人类的平均水平

67
00:02:14,916 --> 00:02:17,600
我们先来看一下2019年的年初

68
00:02:17,600 --> 00:02:18,516
2月份的时候

69
00:02:18,516 --> 00:02:19,766
其实OpenAI

70
00:02:19,766 --> 00:02:21,600
率先的发布了GPT2

71
00:02:21,600 --> 00:02:23,483
作为预训练通用的大模型

72
00:02:23,483 --> 00:02:25,083
也是基于全缩码架构

73
00:02:25,083 --> 00:02:26,600
但是它不像Bert

74
00:02:26,600 --> 00:02:27,316
它Bert

75
00:02:27,316 --> 00:02:30,316
是用了全缩码架构的encorder跟decorder

76
00:02:30,400 --> 00:02:31,316
两个部分

77
00:02:31,833 --> 00:02:33,366
而OpenAI的GPT2

78
00:02:33,366 --> 00:02:36,200
只是用了Transformer的decorder部分

79
00:02:36,200 --> 00:02:38,800
那作为整个预训练通用的单模型

80
00:02:38,800 --> 00:02:41,033
能够生成高度逼真的文本

81
00:02:41,166 --> 00:02:44,766
最终OpenAI在2019年11月份的时候

82
00:02:44,766 --> 00:02:46,366
发布了完整版本

83
00:02:47,116 --> 00:02:48,366
那整体我们可以看到

84
00:02:48,366 --> 00:02:50,600
在整个2019年领域

85
00:02:50,600 --> 00:02:54,033
最核心的就是多语言的模型的兴起

86
00:02:54,083 --> 00:02:57,483
那Facebook的XLM跟mBERT等模型

87
00:02:57,483 --> 00:02:59,400
支持超过100多种语言

88
00:02:59,400 --> 00:03:00,366
非常夸张哦

89
00:03:00,366 --> 00:03:02,800
推动了多语言NLP的发展

90
00:03:03,316 --> 00:03:04,200
了解完NLP

91
00:03:04,200 --> 00:03:06,166
我们还是要看一下CV领域

92
00:03:06,166 --> 00:03:08,200
一个精细化的过程

93
00:03:08,433 --> 00:03:09,800
说实话 2019年

94
00:03:09,800 --> 00:03:10,516
CV领域

95
00:03:10,516 --> 00:03:11,566
进一步的发展

96
00:03:11,566 --> 00:03:13,116
发展成好几个新的内容

97
00:03:13,116 --> 00:03:15,600
第一个就是深层的对抗网络

98
00:03:15,600 --> 00:03:17,716
也就是GAN相关系列的网络

99
00:03:17,716 --> 00:03:18,966
已经走向了成熟

100
00:03:19,283 --> 00:03:21,166
BigGAN跟StyleGAN等

101
00:03:21,166 --> 00:03:23,233
模型在图像生成任务当中

102
00:03:23,233 --> 00:03:24,916
表现非常的出色

103
00:03:24,916 --> 00:03:26,483
生成的图像非常的逼真

104
00:03:26,483 --> 00:03:29,233
而且远超于以前的GAN的模型

105
00:03:29,233 --> 00:03:30,200
展示了GAN

106
00:03:30,200 --> 00:03:33,683
在图像跟视频生成领域的巨大的潜力

107
00:03:33,683 --> 00:03:35,283
推动了AI在艺术创作

108
00:03:35,283 --> 00:03:37,633
和内容生成的相关的应用

109
00:03:37,633 --> 00:03:39,283
虽然我们现在提到GAN

110
00:03:39,283 --> 00:03:40,716
基本上很少人了解了

111
00:03:40,716 --> 00:03:43,283
取而代之的是stability Diffusion

112
00:03:43,283 --> 00:03:44,800
来去代替了GAN

113
00:03:44,833 --> 00:03:45,400
但是

114
00:03:45,400 --> 00:03:48,516
生成式对抗或者生成式相关的内容

115
00:03:48,766 --> 00:03:50,833
主要是由GAN来引起

116
00:03:51,166 --> 00:03:53,400
那在CV领域的精细化过程当中

117
00:03:53,400 --> 00:03:54,716
我们还有第二个

118
00:03:54,716 --> 00:03:56,916
就是图像的分割跟检测

119
00:03:57,083 --> 00:03:59,083
进一步的提升性能

120
00:03:59,083 --> 00:04:03,483
那出现的Mask Scoring R-CNN还有SOLO等算法

121
00:04:03,483 --> 00:04:05,000
在图像分割领域

122
00:04:05,000 --> 00:04:08,516
当中的任务超越了传统的Mask R-CNN

123
00:04:08,566 --> 00:04:11,000
进一步的提高了图像分割的精度

124
00:04:11,433 --> 00:04:13,116
在CV领域的第三个点

125
00:04:13,116 --> 00:04:15,633
就是轻量化的小模型

126
00:04:15,800 --> 00:04:18,366
谷歌在2019年的时候

127
00:04:18,366 --> 00:04:19,883
也提出了efficient

128
00:04:19,883 --> 00:04:21,883
在efficient的测试集当中

129
00:04:21,883 --> 00:04:24,883
实现了40.1%的准确率

130
00:04:24,883 --> 00:04:27,833
同时大幅减少了模型的一个计算量

131
00:04:27,833 --> 00:04:29,316
和参数量

132
00:04:30,233 --> 00:04:31,366
那我们反观

133
00:04:31,366 --> 00:04:33,200
除了NLP跟CV领域

134
00:04:33,200 --> 00:04:35,516
我们来看一下强化学习的突破哦

135
00:04:35,633 --> 00:04:36,366
整体来说

136
00:04:36,366 --> 00:04:37,483
2019年

137
00:04:37,483 --> 00:04:40,800
DeepMind的AlphaStar在星际争霸2当中

138
00:04:40,800 --> 00:04:43,716
击败了顶级的玩家

139
00:04:44,116 --> 00:04:44,633
OpenAI

140
00:04:44,633 --> 00:04:47,800
在Dota 2当中也取得显著的进展

141
00:04:47,800 --> 00:04:49,366
展示了整个强化学习

142
00:04:49,366 --> 00:04:52,000
在复杂任务的应用潜力哦

143
00:04:52,116 --> 00:04:53,566
强化学习的研究

144
00:04:53,566 --> 00:04:56,166
重点逐渐转向从有限的数据当中

145
00:04:56,166 --> 00:04:58,033
去学习泛化能力

146
00:04:58,316 --> 00:04:58,966
那OpenAI

147
00:04:58,966 --> 00:05:00,716
就推出了新的测试环境

148
00:05:00,716 --> 00:05:02,766
来评估算法的泛化能力

149
00:05:02,766 --> 00:05:04,883
而且呀在2019年的时候

150
00:05:04,883 --> 00:05:07,366
OpenAI做了一个非常有意思的事情

151
00:05:07,766 --> 00:05:09,000
收购了Avatar

152
00:05:09,083 --> 00:05:11,083
也就是强化学习里面

153
00:05:11,083 --> 00:05:13,083
经常用到的一些游戏

154
00:05:13,116 --> 00:05:14,166
那这些突破

155
00:05:14,166 --> 00:05:15,316
展示了强化学习

156
00:05:15,316 --> 00:05:17,766
在复杂的任务当中的一个应用潜力

157
00:05:17,766 --> 00:05:20,283
为AI在游戏和现实当中

158
00:05:20,316 --> 00:05:22,233
建立了一个基础

159
00:05:22,766 --> 00:05:24,633
我们现在来到了第二个内容

160
00:05:24,633 --> 00:05:27,516
看一下整个开源框架的崛起哦

161
00:05:27,683 --> 00:05:29,683
首先 2019年蛮有意思

162
00:05:29,683 --> 00:05:31,483
就是PyTorch跟TensorFlow

163
00:05:31,483 --> 00:05:35,083
还在去争夺到底谁才是最好的AI框架

164
00:05:35,316 --> 00:05:36,033
那PyTorch

165
00:05:36,033 --> 00:05:37,233
在2019年的时候

166
00:05:37,233 --> 00:05:38,316
就继续巩固

167
00:05:38,366 --> 00:05:40,883
作为研究领域的主流的AI框架

168
00:05:40,883 --> 00:05:43,483
特别是在NLP领域跟CV领域

169
00:05:43,483 --> 00:05:45,966
它的动态计算图机制好

170
00:05:45,966 --> 00:05:46,600
易用性

171
00:05:46,600 --> 00:05:48,233
使得成为整个学术界

172
00:05:48,233 --> 00:05:50,516
和工业界里面的首选

173
00:05:50,800 --> 00:05:51,400
那同期

174
00:05:51,400 --> 00:05:53,600
2019年TensorFlow

175
00:05:53,600 --> 00:05:56,116
就是谷歌推出的TensorFlow发布了

176
00:05:56,116 --> 00:05:57,366
2.0的版本

177
00:05:57,366 --> 00:05:58,916
引入了即时执行

178
00:05:58,916 --> 00:06:01,116
也就是Eager模式跟Keras

179
00:06:01,116 --> 00:06:02,800
作为默认的API

180
00:06:02,916 --> 00:06:05,433
进一步的简化了模型的开发流程

181
00:06:05,483 --> 00:06:06,683
提升了用户的体验

182
00:06:06,683 --> 00:06:09,400
说白了就是TensorFlow的2.0发布

183
00:06:09,600 --> 00:06:11,166
提升了它的整体应用性

184
00:06:11,200 --> 00:06:12,366
但是呃

185
00:06:12,366 --> 00:06:13,833
回顾历史我们可以看到

186
00:06:13,833 --> 00:06:15,233
TensorFlow 2.0的发布了

187
00:06:15,233 --> 00:06:16,966
Eage模式跟Keras的模式

188
00:06:16,966 --> 00:06:19,716
导致用户的开发变得越来越混乱了

189
00:06:19,716 --> 00:06:20,483
所以最终

190
00:06:20,483 --> 00:06:21,566
TensorFlow是走向了

191
00:06:21,566 --> 00:06:23,316
一个慢慢用的人越来越少

192
00:06:23,316 --> 00:06:24,233
慢慢消亡了

193
00:06:24,233 --> 00:06:25,083
而PyTorch

194
00:06:25,083 --> 00:06:26,083
一枝独大

195
00:06:26,316 --> 00:06:27,033
那同期哦

196
00:06:27,033 --> 00:06:28,433
在2019年的时候

197
00:06:28,433 --> 00:06:30,433
百度的飞桨PaddlePaddle也是

198
00:06:30,433 --> 00:06:32,483
在崛起的百度飞桨

199
00:06:32,483 --> 00:06:33,683
在2019年的时候

200
00:06:33,683 --> 00:06:36,233
就发布了多项重大的更新

201
00:06:36,233 --> 00:06:39,000
包括端侧的推理引擎Paddle Lite 2.0

202
00:06:39,000 --> 00:06:41,316
跟多个面向场景开发的套件

203
00:06:41,316 --> 00:06:42,116
那这里面

204
00:06:42,116 --> 00:06:45,566
更广为人熟知的就是Paddle OCR

205
00:06:45,566 --> 00:06:46,366
这么一个套件

206
00:06:46,366 --> 00:06:48,400
宗米之前应该跟很多人去了解

207
00:06:48,400 --> 00:06:50,966
也是发现很多的ISV用户

208
00:06:50,966 --> 00:06:53,433
会经常用到Paddle的各种各样的套件

209
00:06:53,433 --> 00:06:55,116
特别是Paddle OCR的套件

210
00:06:55,166 --> 00:06:56,516
并且Paddle开源了

211
00:06:56,516 --> 00:06:57,833
在2019年的时候

212
00:06:57,833 --> 00:07:00,000
真正开源了它的PaddlePaddle框架

213
00:07:00,000 --> 00:07:00,916
进一步丰富了

214
00:07:00,916 --> 00:07:04,000
整个百度的开源框架的生态系统

215
00:07:04,600 --> 00:07:05,000
那另外

216
00:07:05,000 --> 00:07:07,800
我们还有好几个不同的开源的引擎

217
00:07:07,800 --> 00:07:08,766
和开源的库

218
00:07:08,766 --> 00:07:11,166
首先第一个开源框架也是MXNet了

219
00:07:11,166 --> 00:07:12,483
也就是木沐老师

220
00:07:12,483 --> 00:07:14,916
亚马逊大力的去推广MXNet

221
00:07:15,200 --> 00:07:17,033
MXNet就支持多元的编程

222
00:07:17,033 --> 00:07:18,633
C++呀、PyTorch

223
00:07:18,633 --> 00:07:21,166
并且在AWS的生态当中

224
00:07:21,166 --> 00:07:22,600
占据了重要的地位

225
00:07:22,600 --> 00:07:25,200
也就是AWS主推MXNet

226
00:07:25,233 --> 00:07:28,433
并且把木沐招聘进来AWS

227
00:07:28,433 --> 00:07:31,916
作为整个亚马逊的AI的首席科学家

228
00:07:31,916 --> 00:07:32,433
那虽然

229
00:07:32,433 --> 00:07:34,800
现在木沐老师已经离开亚马逊

230
00:07:34,800 --> 00:07:35,883
去创业了

231
00:07:36,166 --> 00:07:38,283
另外的话我们反观另外一个社区

232
00:07:38,283 --> 00:07:39,516
就是HuggingFace

233
00:07:39,600 --> 00:07:40,716
2019年的时候

234
00:07:40,716 --> 00:07:42,966
HuggingFace正式的发布了Transformer库

235
00:07:43,033 --> 00:07:45,033
现在我们讲到大模型

236
00:07:45,033 --> 00:07:47,916
不管是大语言模型还是多模态大模型

237
00:07:48,116 --> 00:07:48,433
大家呀

238
00:07:48,433 --> 00:07:51,233
都会上HuggingFace里面去下载相关模型

239
00:07:51,233 --> 00:07:52,483
或者自己发布的模型

240
00:07:52,483 --> 00:07:54,966
会发布到HuggingFace这个社区

241
00:07:54,966 --> 00:07:56,366
那2019年的时候

242
00:07:56,366 --> 00:07:57,883
HuggingFace正式的发布了

243
00:07:57,883 --> 00:07:59,200
它的Transformer库

244
00:07:59,233 --> 00:08:01,000
专注于自然语言处理

245
00:08:01,000 --> 00:08:01,883
特别是基于Transformer

246
00:08:01,883 --> 00:08:02,966
架构

247
00:08:03,083 --> 00:08:06,233
迅速的成为NLP领域的整个标杆工具

248
00:08:06,233 --> 00:08:07,966
和标杆的一个社区了

249
00:08:08,166 --> 00:08:08,716
另外的话

250
00:08:08,716 --> 00:08:09,483
AutoML

251
00:08:09,483 --> 00:08:12,033
我记得华为在2019年的时候

252
00:08:12,033 --> 00:08:14,433
有真正的第一个天才少年

253
00:08:14,433 --> 00:08:15,883
就是搞AutoML

254
00:08:15,883 --> 00:08:16,716
那这个时候

255
00:08:16,716 --> 00:08:19,000
谷歌就推出了AutoML的工具

256
00:08:19,000 --> 00:08:20,966
降低了AI模型开发的门槛

257
00:08:21,166 --> 00:08:22,316
使得非专业的用户

258
00:08:22,316 --> 00:08:24,483
也能构建高性能的模型

259
00:08:24,483 --> 00:08:26,166
后来AutoML的技术路线

260
00:08:26,166 --> 00:08:27,800
也越来越少了

261
00:08:27,800 --> 00:08:30,033
因为AutoML说实话太消耗资源了

262
00:08:30,033 --> 00:08:32,716
还不如用人来去设计一个模型

263
00:08:32,716 --> 00:08:34,683
那可能后面都殊途同归

264
00:08:34,683 --> 00:08:37,283
大家都用Transformer这个模型的架构了

265
00:08:37,283 --> 00:08:38,083
就没有必要

266
00:08:38,083 --> 00:08:40,200
去花费大量的一个积极资源

267
00:08:40,200 --> 00:08:42,683
去搜索我们的模型架构了

268
00:08:43,366 --> 00:08:44,316
第三个内容

269
00:08:44,316 --> 00:08:47,883
我们看一下整个AI的芯片和硬件

270
00:08:47,883 --> 00:08:50,200
在2019年的时候的一个发布

271
00:08:50,716 --> 00:08:51,316
整体来说

272
00:08:51,316 --> 00:08:52,000
AI的芯片

273
00:08:52,000 --> 00:08:52,883
在2019年

274
00:08:52,883 --> 00:08:54,683
是取得一个很重要的突破

275
00:08:54,883 --> 00:08:56,833
华为的昇腾发布

276
00:08:56,833 --> 00:08:57,316
说实话

277
00:08:57,316 --> 00:08:59,716
华为发布了全球算力最强的AI芯片

278
00:08:59,716 --> 00:09:00,800
昇腾910

279
00:09:00,800 --> 00:09:01,483
它的算力

280
00:09:01,483 --> 00:09:04,166
是居国际顶尖的AI芯片的两倍

281
00:09:04,166 --> 00:09:05,200
就是英伟达的两倍

282
00:09:05,200 --> 00:09:06,233
对比起V100

283
00:09:06,316 --> 00:09:07,000
整体标志

284
00:09:07,000 --> 00:09:08,883
中国在AI芯片的一个领域

285
00:09:08,883 --> 00:09:10,000
重大的突破

286
00:09:10,400 --> 00:09:10,833
另外的话

287
00:09:10,833 --> 00:09:14,233
2019年谷歌的TPU也发布了第三代

288
00:09:14,233 --> 00:09:14,833
那整体

289
00:09:14,833 --> 00:09:17,233
支持大规模的AI训练和推理

290
00:09:17,233 --> 00:09:20,800
推动了整个Bert模型的进步和突破

291
00:09:20,833 --> 00:09:22,800
那同期我们反观看一下

292
00:09:22,800 --> 00:09:25,633
宇宙最强的英伟达的硬件的创新

293
00:09:25,883 --> 00:09:26,433
图灵架构

294
00:09:26,433 --> 00:09:27,683
在2019年的时候

295
00:09:27,683 --> 00:09:30,083
成为整体的AI的主流

296
00:09:30,083 --> 00:09:31,200
支持浮点和整形运算

297
00:09:31,200 --> 00:09:33,366
自适应的着色的技术

298
00:09:33,366 --> 00:09:36,166
跟全适应的显存的架构

299
00:09:36,166 --> 00:09:38,116
提升整体的游戏性能

300
00:09:38,200 --> 00:09:40,366
那2019年的6月份

301
00:09:40,600 --> 00:09:43,400
英伟达还推出了它的一个DGX

302
00:09:43,400 --> 00:09:45,433
一个Superpod超级计算机

303
00:09:45,433 --> 00:09:47,600
里面又内置了96台

304
00:09:47,600 --> 00:09:50,233
英伟达的DGX的整体系统

305
00:09:50,633 --> 00:09:51,716
那2019年的时候

306
00:09:51,716 --> 00:09:53,800
英伟达还用了69亿美元

307
00:09:53,800 --> 00:09:56,083
去收购了一个网络技术的公司

308
00:09:56,083 --> 00:09:57,000
叫做Mellanox

309
00:09:57,000 --> 00:09:58,516
增加它在数据中心

310
00:09:58,566 --> 00:10:02,366
跟高性能计算领域的相关的能力

311
00:10:02,400 --> 00:10:03,116
那Mellanox

312
00:10:03,116 --> 00:10:04,766
后面也会成为英伟达

313
00:10:04,883 --> 00:10:06,483
后续的网络里面

314
00:10:06,483 --> 00:10:07,516
很重要的一环

315
00:10:08,083 --> 00:10:08,766
那同期

316
00:10:08,766 --> 00:10:09,833
英伟达这个时候

317
00:10:09,833 --> 00:10:12,800
在2019年的时候其实是收购了Habana Lab

318
00:10:12,966 --> 00:10:15,166
虽然英伟达现在已经萎靡不振了

319
00:10:15,166 --> 00:10:17,516
但是英伟达以20亿美元

320
00:10:17,566 --> 00:10:21,366
收购了以色列的AI的芯片制造商Habana

321
00:10:21,366 --> 00:10:22,233
那旨在

322
00:10:22,233 --> 00:10:23,916
去增强它在数据中心

323
00:10:23,916 --> 00:10:27,000
跟AI芯片的市场的竞争力

324
00:10:27,000 --> 00:10:28,083
那后面

325
00:10:28,316 --> 00:10:30,400
在Habana就推出了Gaudi 1/2/3

326
00:10:30,400 --> 00:10:31,000
不过Gaudi

327
00:10:31,000 --> 00:10:34,433
没有成为一个很好的市场的选择

328
00:10:34,483 --> 00:10:35,483
那不管怎么样

329
00:10:35,483 --> 00:10:36,833
在2019年

330
00:10:36,833 --> 00:10:38,833
这些AI芯片的进展

331
00:10:38,833 --> 00:10:40,116
就为整个深度学习

332
00:10:40,116 --> 00:10:42,116
和大规模的AI的计算

333
00:10:42,116 --> 00:10:43,433
提供了硬件的支持

334
00:10:43,433 --> 00:10:46,000
整体推动AI基础的建设

335
00:10:46,083 --> 00:10:48,766
跟AI技术的普及和对应的应用

336
00:10:49,000 --> 00:10:51,600
现在我们看一下相关的一个应用了

337
00:10:51,600 --> 00:10:52,400
AI的应用了

338
00:10:52,400 --> 00:10:53,833
第一个就是自动驾驶

339
00:10:53,833 --> 00:10:55,633
说实话在2019年的时候

340
00:10:55,633 --> 00:10:56,966
自动驾驶整体商业化

341
00:10:56,966 --> 00:10:58,883
是受到一些阻碍

342
00:10:58,883 --> 00:11:00,566
发展没有那么的好

343
00:11:00,566 --> 00:11:01,633
2019年的时候

344
00:11:01,633 --> 00:11:03,566
自动驾驶领域遭遇到瓶颈

345
00:11:03,566 --> 00:11:05,366
整体商业化的扩展速度

346
00:11:05,400 --> 00:11:06,966
明显的放缓了

347
00:11:06,966 --> 00:11:09,000
例如Waymo的首席执行官

348
00:11:09,000 --> 00:11:09,466
了

349
00:11:09,516 --> 00:11:11,966
约翰科拉夫奇科就表示

350
00:11:11,966 --> 00:11:13,366
自动驾驶的汽车

351
00:11:13,400 --> 00:11:16,400
可能永远没有办法在全路况条件下

352
00:11:16,400 --> 00:11:17,400
去行驶

353
00:11:17,400 --> 00:11:19,883
所以当时候还是比较悲观

354
00:11:19,883 --> 00:11:20,633
而特斯拉

355
00:11:20,633 --> 00:11:23,766
也将自动驾驶出租车的最后的期限

356
00:11:23,766 --> 00:11:27,200
呃从2019年就推迟到2022年了

357
00:11:27,716 --> 00:11:28,000
另外的话

358
00:11:28,000 --> 00:11:30,316
我们看一下AI安全方面

359
00:11:30,400 --> 00:11:31,683
在AI安全方面

360
00:11:31,683 --> 00:11:35,116
其实DeepFake在2019年是大放光彩

361
00:11:35,116 --> 00:11:36,166
DeepFake技术

362
00:11:36,166 --> 00:11:39,233
利用一些被生成的虚假的视频

363
00:11:39,233 --> 00:11:41,366
引发了整体AI技术的滥用

364
00:11:41,566 --> 00:11:43,516
而虚假的信息的传播

365
00:11:43,516 --> 00:11:45,233
能够生成很逼真的名人

366
00:11:45,233 --> 00:11:47,916
或者政治人物的一些演讲哦

367
00:11:48,000 --> 00:11:51,116
引发了对AI技术的滥用的担忧

368
00:11:51,166 --> 00:11:54,000
那Facebook就宣布了在2019年的时候

369
00:11:54,000 --> 00:11:55,766
一项奖金

370
00:11:55,766 --> 00:11:58,600
高达1,000万美金的竞赛

371
00:11:58,600 --> 00:12:01,633
开启了DeepFake假视频的自动检测

372
00:12:01,633 --> 00:12:03,683
相关的技术的研究

373
00:12:04,116 --> 00:12:05,116
那在立法层面

374
00:12:05,116 --> 00:12:07,316
公众对人脸识别的技术的隐私

375
00:12:07,316 --> 00:12:08,633
和肖像的滥用问题

376
00:12:08,633 --> 00:12:10,316
其实也感到非常担忧了

377
00:12:10,316 --> 00:12:13,033
所以这又促使了美国和欧洲的维权

378
00:12:13,033 --> 00:12:14,316
也LGTP的人士

379
00:12:14,316 --> 00:12:16,116
还有一些呃安全的人士

380
00:12:16,116 --> 00:12:17,833
去推动相关的立法

381
00:12:17,833 --> 00:12:19,200
2019年5月份

382
00:12:19,316 --> 00:12:21,833
旧金山就成为美国第一个禁止警察

383
00:12:21,833 --> 00:12:23,033
其他政府人员

384
00:12:23,366 --> 00:12:25,316
使用人脸识别的大城市

385
00:12:25,316 --> 00:12:26,600
其实后面

386
00:12:26,600 --> 00:12:27,766
很多国外的城市

387
00:12:27,766 --> 00:12:29,483
都开始禁止人脸识别了

388
00:12:29,483 --> 00:12:31,516
那因为在2019年之后

389
00:12:31,516 --> 00:12:32,600
2020年

390
00:12:32,800 --> 00:12:36,283
应该是新冠疫情的大规模的来临

391
00:12:36,283 --> 00:12:38,316
你会发现各种各样的人脸技术

392
00:12:38,316 --> 00:12:40,000
也是开放出去了

393
00:12:40,166 --> 00:12:40,916
让更多的人

394
00:12:40,916 --> 00:12:41,566
可能在家里

395
00:12:41,566 --> 00:12:43,566
也能够做到一个人脸识别

396
00:12:43,566 --> 00:12:45,166
包括苹果的手机

397
00:12:45,166 --> 00:12:46,033
那这一事件

398
00:12:46,033 --> 00:12:48,366
整体促使了AI的科技公司跟社

399
00:12:48,366 --> 00:12:49,366
会的各界

400
00:12:49,366 --> 00:12:53,116
加强对AI的技术的监管和防范的作用

401
00:12:53,133 --> 00:12:55,400
我们现在来一个最后的总结哦

402
00:12:55,516 --> 00:12:56,916
2019年说实话

403
00:12:56,916 --> 00:12:59,116
AI在最重要的就是在NLP

404
00:12:59,116 --> 00:13:02,083
也就是自然语言处理相关的领域

405
00:13:02,083 --> 00:13:03,283
发布了GPT2

406
00:13:03,633 --> 00:13:06,800
那计算机视觉领域

407
00:13:06,833 --> 00:13:07,883
就CV领域

408
00:13:07,883 --> 00:13:09,600
就出现了大量的小模型

409
00:13:09,600 --> 00:13:10,600
GAN的技术

410
00:13:10,600 --> 00:13:13,033
在一个艺术创作当中的一个应用

411
00:13:13,233 --> 00:13:14,400
强化学习方面

412
00:13:14,400 --> 00:13:15,516
谷歌的DeepMind

413
00:13:15,566 --> 00:13:19,116
AlphaStar就使用强化学习

414
00:13:19,116 --> 00:13:22,000
战胜了星际争霸2顶尖的选手

415
00:13:22,000 --> 00:13:23,483
无人驾驶的技术的推进

416
00:13:23,483 --> 00:13:24,633
还有医疗AI

417
00:13:24,633 --> 00:13:26,716
在医疗的一个诊断的应用方面

418
00:13:26,716 --> 00:13:28,433
取得很大的进展

419
00:13:28,566 --> 00:13:29,033
同时

420
00:13:29,033 --> 00:13:31,683
AI芯片跟跨学科的应用和伦理问题

421
00:13:31,683 --> 00:13:32,916
整体成为焦点

422
00:13:32,916 --> 00:13:35,033
那今天回顾2019年的内容

423
00:13:35,033 --> 00:13:35,833
就到这里为止

424
00:13:35,833 --> 00:13:36,433
谢谢各位

425
00:13:36,433 --> 00:13:37,083
拜了个拜

